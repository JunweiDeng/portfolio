<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>Home</title>
	<link rel="stylesheet" href="css/style.css">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-160820772-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-160820772-1');
</script>

</head>
<body>
  <div class="skip"><a href="#main">Skip to Main Content</a></div>
    <header>
      <img src="images/logo.png" alt="logo picture" id = "logo">
      <nav>
        <ul class="nav_links">
          <li class="nav_item"><a href="index.html">About</a></li>
          <li class="nav_item"><a href="education.html">Education</a></li>
          <li class="nav_item"><a href = "research.html"><b><u>Research</u></b></a></li>
          <li class="nav_item"><a href = "work_experience.html">Work Experience</a></li>
        </ul>
    </nav>
  </header>
<main>
<p id = "main">
Currently I do research in <a href="http://foreseer.si.umich.edu/">Foreseer Group@UM</a>
 on machine learning models for structured-data. I once worked in 
 <a href = "http://acalab.sjtu.edu.cn/EN/Default.aspx">Advanced 
 Computer Architecture Laboratory@SJTU</a> on Biomedical Image processing and analysis, 
 and <a href = "http://wanglab.sjtu.edu.cn/en/Default.aspx">Wireless Networking and Artificial 
 Intelligence Lab@SJTU</a> on <a href = "http://wisp5.wispsensor.net/">Wireless Identification 
 and Sensing Platform (WISP)</a>.
</p>

<div class="parallax3" id="p3"></div>
<div id="grid3">
  <div class = "siglogo">
  <img src="images/pic2.png_RESULT.jpg" alt = "siglogo">
</div>
<div class = "sig">
<a href="https://dlnext.acm.org/doi/abs/10.1145/3306214.3338593">
<h1>Noise reduction with image inpainting: an application in clinical data diagnosis</h1>
              </a>
              <br>
              <p>
              <a href="http://www.cs.sjtu.edu.cn/PeopleDetail.aspx?id=402">Jing Ke</a>,
              <strong>Junwei Deng</strong>,
              Yizhou Lu
              <br>
              <em>SIGGRAPH(poster)</em>, 2019.
              <br>
              <p></p>
              <p>For cytology, pathology or histology image analysis, whether 
                performed by computer-aided algorithms or human experts, a general 
                issue is to exclude the disturbance caused by noisy objects, 
                especially when appeared with high similarities in shape, color 
                and texture with target cell or tissues. In this paper, we introduce 
                a novel model to reduce such type of noisy objects with large quantity
                 and distribution in the microscope images based on deep learning and
                  hand-craft features. The model experimentally reduces the false positives
                   without effect on objects of interest for cancer detection. Moreover,
                    it also provides much distinct images for human experts for the final diagnosis.</p>
</div>
</div>


<div class="parallax4" id="p4"></div>
<div id="grid4">
  <div class = "dictalogo">
  <img src="images/2.jpg" alt = "dictalogo">
</div>
<div class = "dicta">
<a href="https://ieeexplore.ieee.org/document/8946065">
<h1>Assessment and Elimination of Inflammatory Cell: A Machine Learning Approach in Digital Cytology</h1>
              </a>
              <br><p>
              <a href="http://www.cs.sjtu.edu.cn/PeopleDetail.aspx?id=402">Jing Ke</a>, 
              <strong>Junwei Deng</strong>, 
              Yizhou Lu,
              <a href="https://people.csiro.au/W/D/Dadong-Wang">Dadong Wang</a>,
              <a href="https://research.unsw.edu.au/people/dr-yang-song">Yang Song</a>,
              Huijuan Zhang
              
              <br>
              <em>DICTA</em>, 2019 & <strong>(Oral Presentation)</strong>
              <p></p>
              <p>In automatic cytology image diagnosis, the falsepositive
                or false-negative often come up with inflammatory cells
                that obscure the identification of abnormal or normal cells. These
                phenotypes are presented in the similar appearance in shape,
                color and texture with cells to detect. In this paper, to evaluate
                the inflammation and eliminate their disturbances of recognizing
                cells of interests, we propose a two-stage framework containing
                a deep learning based neural network to detect and estimate
                the proportions of inflammatory cells, and a morphology based
                image processing architecture to eliminate them from the digital
                images with image inpainting. For performance evaluation, we
                apply the framework to our collected real-life clinical cytology
                slides presented with a variety of complexities. We evaluate the
                tests on sub-images cropped from 49 positive and 49 negative
                slides from different patients, each at the magnification rate of
                40. The experiments shows an accurate profile of the coverage
                of inflammation in the whole slide images, as well as their
                proportion in all the cells presented in the image. Confirmed
                by cytotechnologists, more than 96.0% of inflammatory cells
                are successfully detected at pixel level and well-inpainted in the
                cytology images without bringing new recognition problem.</p>
</div>
</div>

<div class="parallax5" id="p5"></div>
<div id="grid5">
  <div class = "ismblogo">
  <img src="images/resnet.jpg" alt = "ismblogo">
</div>
<div class = "ismb">
 <a href="https://f1000research.com/posters/8-1506">
                <h1>Detection, segmentation and classification for cervical cytology image</h1>
              </a>
              <p>
              <br>
              Changchang Liu,
              <strong>Junwei Deng</strong>, 
              Yiqing Shen,
              <a href="http://www.cs.sjtu.edu.cn/PeopleDetail.aspx?id=402">Jing Ke</a>
              <br>
              <em>ISMB(poster)</em>, 2019
              <br></p>
              <p></p>
              <p>We design a new framework containing of two neural networks, as one for cell detection and segmentation by pixel-wise annotation and the other for subtype classification by image-level labeling. This model significantly saves the manual annotation effort while preserving the same accuracy in cell boundary location, nuclei location, and subtype classification. Moreover, as the classification result is crucial to computer-aided diagnosis, and the accuracy of neural networks can be reliably achieved at the expense of more training data, we require only image-level labeling to improve this system in the future work.</p>
</div>
</div>

<div class="parallax6" id="p6"></div>
<div id="grid6">
  <div class = "hikmlogo">
  <img src="images/1111.jpg" alt = "hikmlogo">
</div>
<div class = "hikm">
  <a href="">
 <h1>An Accurate Neural Network for Cytologic Whole-Slide Image Analysis</h1>
              </a>
              <br>
              <p>
              <strong>Junwei Deng</strong>,
              Yizhou Lu,
              <a href="http://www.cs.sjtu.edu.cn/PeopleDetail.aspx?id=402">Jing Ke</a>
              <br>
              <em>HIKM@ACSW</em>, 2020 & <strong>(Best Student Paper)</strong>
              <br>
              <a href="https://github.com/SJTU-AI-GPU/TwoStageCellSegmentation">pytorch code</a>
              <p></p>
              <p>Typically, high accuracy in deep learning are achieved by large
                dataset in pixel-wise labeling for segmentation or image-level labeling
                for classification. However, in biomedical domain, the challenge
                is not only the availability of image data itself, but also the acquisition
                of relevant annotations for these images from clinicians. In
                this work, we propose a novel two-stage architecture to jointly
                perform the tasks of detection, segmentation and classification
                of abnormal cells and cancer. Compared with one-step detection
                for all the catalogues, we combine the advantage of image-level
                and pixel-level labeling in our deep learning based framework.
                We use the detection of lesions in cervical clinical dataset as a
                case study for performance evaluation. In the first stage, a hybrid
                ResNet and U-Net architecture is designed to predict three
                catalogues of nuclei, cytoplasm and background with pixel-wise
                labeled segmentation map. In the second stage, a residual learning
                based model is applied to the identified nuclei for subtype classification.
                Confirmed with cytotechnologist, the proposed model
                is estimated to efficiently deduct more than 90% annotation burden
                compared with pixel-wise labeling approach. Moreover, the
                proposed two-stage approach model outperforms one-stage neural
                network in segmentation and classification for objects with high
                similarities in appearance.</p>
</div>
</div>


<div class="wrapper">
</div>
<footer>Junwei Deng, SI539 Course Project</footer>
</main>
</body>